description: An agentic flow designed to assist in creating new astonish agentic flows.
nodes:
  - name: get_overall_idea
    type: input
    prompt: |
      Welcome to the Agentic Flow Creator! I'm here to help you design a new agentic flow.
      Please provide an overall description of the flow you want to create. What's the main goal and what should it do?
    output_model:
      overall_idea: str
    user_message:
      - "Thank you for your idea! Let's now check which tools are available to help us create this flow."

  - name: fetch_available_tools
    type: llm
    tools: True
    tools_selection:
      - shell_command
    tools_auto_approval: False
    system: |
      You are a system assistant tasked with fetching the list of available tools.
      Run `astonish tools list` using shell_command.
      Parse the output and create a structured list of available tools. Each item should be a dictionary with 'name' and 'description' keys.
    prompt: |
      Use the shell_command tool to run: `astonish tools list`
      Parse the output into a list of dictionaries, e.g., `[{{"name": "tool1", "description": "..."}}, {{"name": "tool2", "description": "..."}}]`.
    output_model:
      available_tools: list
    print_state: False
    user_message:
      - "Great! Now I have the list of available tools. Let's generate the YAML for your agentic flow."

  - name: generate_or_refine_yaml
    type: llm
    system: |
      You are an expert YAML agentic flow designer and refiner.
      Your primary goal is to generate or refine a complete agentic flow YAML string based on user requirements, feedback, and strict framework rules.

      **Operational Modes:**
      1. **Initial Generation:** If 'current_yaml' input is missing, null, or empty, generate a NEW, complete YAML based on 'overall_idea' and 'available_tools', using the rules and example.
      2. **Refinement:** If 'current_yaml' and 'yaml_feedback' are provided, carefully modify the 'current_yaml' string ONLY to address the specific feedback, ensuring the result is valid YAML respecting all rules. Do not regenerate unrelated parts.
    prompt: |
      # --- Inputs ---
      # User's overall idea (for initial generation):
      {overall_idea}

      # Available tools (Name & Description):
      {available_tools}

      # Previous YAML Version (if refining - will be absent on first run):
      {current_yaml}

      # Validation Error (if refining - will be absent on first run):
      {validation_error}
      
      # If there is a validation error above, the YAML is invalid. Fix it based on the error message.
      # Only change the part of the YAML that is invalid, and keep the rest of the YAML as it is.
      # For the parts affected by the validation error, make sure to follow the rules and example, double check the fields allowed type and example for that.

      # User Feedback on Previous Version (if refining - will be absent on first run):
      {yaml_feedback}

      **Framework Rules:**
      1. Valid `type`: 'input', 'llm'.
      2. `input`: Only for direct user interaction in the final agent. Fields: name, type, prompt, output_model, options, user_message (optional).
      3. `llm`: For logic, generation, tool calls. Fields: name, type, system, prompt, output_model, user_message (optional), tools (optional, bool), tools_selection (optional, list[str]).
      4. Tools: 'tools: True' requires 'tools_selection' listing tools from 'Available Tools'. Tools are used BY 'llm' nodes.
      5. `output_model`: Dictionary mapping string variable names to string types ("str", "list", "dict", "bool", "int"). Example: `{{"results": "list"}}`.
      6. `options` is a variable from output_model of type list or a list of strings (e.g., ["option1", "option2"]). Whenever possible, use the 'options' field to limit user input to a specific set of choices, and use the options in the flow, reducing the amount of agent calls.
        Good Examples: 
          - `"options": ["option1", "option2"]` for a list of strings.
          - `"options": [options_list]` for a variable from output_model of type list.

        Bad examples (not allowed):
          - `"options": option1` (not a list)
          - `"options": "option1, option2"` (not a list)
          - `"options": [{{"option1}}]` (should never use curly braces in the options list)

      6.1. `options` is very helpful if the agent from previous node is a list of strings, and you want to limit the user input to one of the options. Example: `{{"options": ["option1", "option2"]}}`. If the options is a output_model variable, it should just mention the variable name. Example: `{{"options": [options_list]}}`, no curly braces around the list variable name.
      6.2. `options` cannot be a complex expression like lamba, it should always be a list, and can be strings or a variable from output_model of type list.
      6.3. `options` must be a list, it CANNOT be something like `{{"options": option1}}` or `{{"options": "option1, option2"}}`, instead it must use the dash (-) for each item, according to the YAML schema for lists.
      7. `user_message`: Optional LIST of strings (variable names from output_model) for display. Omit if not needed. Example: `["final_summary"]`. It should be an output_model variable name, or a string. It must be used everytime the information is required to be displayed to the user.
      8. Ensure unique node names, correct variable usage between nodes (`{{variable}}`), valid lambda functions for conditions (`"lambda x: x['var'] == True"`).
      9. Structure: Top-level 'description', 'nodes' (list of node dicts), 'flow' (list of transition dicts like `{{'from': 'nodeA', 'to': 'nodeB'}}` or using 'edges').
      10. Loops: If iteration is needed, implement using an index variable, conditional edges, and index increment nodes.
        Loop Detection Rule:
          If an llm node's prompt refers to a variable of type list (e.g., changed_files, items_to_process) and the node uses a tool or operation that processes a single item (e.g., read_file, analyze_entry, summarize_text), then automatically implement a loop structure using:

          current_index (type: int)
          A node that selects the current item (e.g., current_file = changed_files[current_index])
          A node that processes the item and appends to a shared result (e.g., file_contents)
          An increment node for current_index
          A loop condition in flow.edges using:
          "lambda x: x['current_index'] < len(x['changed_files'])"

      11. Conditions: Use 'edges' with lambda functions for branching.
      12. All the conditional logic should be handled within the flow section, it should use lambda for checking conditions of the output_model variables.
      13. When using the shell_command tool, make sure that the command to be run is in the prompt.
      14. When working with items to be appended to a list, make sure to provide the list in the prompt before the item to be appended. For example, if you have a list called 'collected_summaries', make sure to provide it in the prompt before the item to be appended.
      15. Always remember, to inject content use single curly braces, and to show as an example use double curly braces.
      16. Every prompt must be at least a single content injection by using the single curly braces. So it has the context of the previous node. Multiple injections are allowed, but at least one is required.

      # --- Comprehensive Example Flow (Study this structure and apply principles) ---
      ```yaml
      description: Example Research Agent Flow
      nodes:
        - name: get_topic
          type: input
          prompt: |
            What topic do you want to research?
          output_model: 
            research_topic: str
        - name: search_web
          type: llm
          system: |
            You are a research assistant that performs high-quality web searches on behalf of the user.
            Your goal is to find relevant, trustworthy, and up-to-date information about a specific topic.
            Use clear keywords and aim to retrieve results that would be genuinely helpful for someone doing research or looking for answers.
          prompt: |
            Please perform a web search to gather useful and recent information on the following topic:
            
            Topic: "{{research_topic}}"
            
            Make sure to include credible sources and provide a variety of perspectives if relevant.
            Set current_index to 0.
          output_model:
            search_results: list
            current_index: int
          tools: true
          tools_selection:
            - tavily-search  

        - name: process_one_result
          type: llm
          system: |
            Extract key info from a search result.
          prompt: |
            collected_summaries:
            {{collected_summaries}}

            search_results:
            {{search_results}}

            Process result at index {{current_index}} from search results and apprend to the collected_summaries.

          output_model: 
            collected_summaries: list
          user_message:
            - collected_summaries

        - name: increment_index
          type: llm
          prompt: | 
            Increment current_index: {{current_index}}. Output current_index + 1.
          output_model: 
            current_index: int
          user_message:
            - current_index

        - name: final_report
          type: llm
          system: |
            Generate a consolidated report from collected summaries.
          prompt: |
            Generate final report using collected summaries, one news per line with a nice format.
            
            collected_summaries:
            {{collected_summaries}}
          output_model: 
            report: str
          user_message:  
            - report

        - name: new_search
          type: input
          prompt: |
            Do you want to search for another topic?
          output_model: 
            research_topic: str
          options:
            - "yes"
            - "no"
            - collected_summaries #example of using a variable from output_model as options
      flow:
        - from: START
          to: get_topic
        - from: get_topic
          to: search_web
        - from: search_web
          to: process_one_result
        - from: process_one_result
          to: increment_index
        - from: increment_index
          edges:
            - to: process_one_result
              condition: "lambda x: x['current_index'] < len(x['search_results'])"
            - to: final_report
              condition: "lambda x: not x['current_index'] < len(x['search_results'])"
        - from: final_report
          to: new_search
        - from: new_search
          edges:
            - to: get_topic
              condition: "lambda x: x['research_topic'] == 'yes'"
            - to: END
              condition: "lambda x: x['research_topic'] == 'no'"
      ```
      # --- End Example ---

      # --- Task ---
      Execute ONE of the Operational Modes defined in the system prompt based on the presence and content of 'current_yaml' and 'yaml_feedback'.

      Output the resulting YAML string (either newly generated, refined, or passed-through for saving) as 'current_yaml', and the boolean 'refinement_complete' flag. Output ONLY the required JSON object.
    output_model:
      current_yaml: str
    print_prompt: False

  - name: summarize_and_display_yaml
    type: llm
    system: |
      You are an assistant summarizing and presenting an agentic flow YAML.
      1. Briefly summarize the purpose and main steps of the flow based on the YAML content.
      2. Format the full YAML content within a markdown code block for display.
      3. Prepare the text for the feedback prompt, instructing user to provide feedback or type 'SAVE'.
    prompt: |
      # Current Agentic Flow YAML:
      {current_yaml} # Input from generate_or_refine_yaml

      # Task:
      1. Analyze the YAML and write a brief summary in 'flow_summary'.
      2. Create 'formatted_yaml_display' containing the full YAML in a markdown code block.
      3. Create 'feedback_prompt_text'. Example: "{{summary}}\n---\n**Current YAML:**\n{{yaml_display_block}}\n---\nReview the YAML. Provide specific feedback for changes, or type 'SAVE' if satisfied and ready to finalize."
    output_model:
      flow_summary: str
      formatted_yaml_display: str
      feedback_prompt_text: str

  - name: user_approval
    type: input
    prompt: |
      {flow_summary}
      ---
      {formatted_yaml_display}

      Please review the YAML above select 'approve' if you are satisfied with it, or 'refine' if you want to make changes.
    output_model:
      yaml_feedback: str
    options:
      - "approve"
      - "refine"

  - name: get_yaml_feedback
    type: input
    prompt: |
      Sure, let's refine the YAML. Please provide specific feedback on what you would like to change or improve.
      You can refer to the YAML structure, node names, or any specific part of the flow.
    output_model:
      yaml_feedback: str
    user_message:
      - "Thank you for your feedback! Let's refine the YAML based on your suggestions."

  - name: validate_yaml
    type: llm
    tools: True
    tools_selection:
      - validate_yaml_with_schema
    tools_auto_approval: False
    system: |
      You are a YAML validation assistant using the 'validate_yaml_with_schema' tool.
      Your task is to validate the provided 'content_yaml' against the predefined 'Agentic Flow Schema' defined below.
      Analyze the tool's output dictionary to determine validity.
    prompt: |
      schema:
      ```yaml
      type: map
      mapping:
        description: {{type: str, required: True}}
        nodes:
          type: seq
          required: True
          sequence:
            - type: map
              mapping:
                name: {{type: str, required: True}}
                type: {{type: str, required: True, enum: ['input', 'llm']}}
                options: {{type: seq, required: False, sequence: [{{type: str}}]}}
                system: {{type: str, required: False}}
                prompt: {{type: str, required: True}}
                output_model: 
                  type: map
                  required: True
                  mapping: 
                    regex;(.+): 
                      type: str
                user_message: {{type: seq, required: False, sequence: [{{type: str}}]}}
                tools: {{type: bool, required: False}}
                tools_selection: {{type: seq, required: False, sequence: [{{type: str}}]}}
                print_state: {{type: bool, required: False}}
        flow:
          type: seq
          required: True
          sequence:
            - type: map
              mapping:
                from: {{type: str, required: True}}
                to: {{type: str, required: False}}
                edges:
                  type: seq
                  required: False
                  sequence:
                    - type: map
                      mapping:
                        to: {{type: str, required: True}}
                        condition: {{type: str, required: True}}
      ```

      content_yaml:
      {current_yaml}

      # Task:
      Call the 'validate_yaml_with_schema' tool with the content_yaml as input and the schema.
      Provide in the validation_error full response from the tool in case of error.
      Provide in the validation_user_message the user message with saying if the validation failed or succeeded.
    output_model:
      is_yaml_valid: bool
      validation_error: list
      validation_user_message: str
    user_message:
      - validation_user_message

  - name: suggest_flow_name
    type: llm
    system: |
      Generate a short, descriptive snake_case name based on the flow's description or purpose found within the final YAML.
    prompt: |
      # Final Flow YAML:
      {current_yaml} # The final YAML after refinement loop

      Generate a suitable snake_case name (e.g., example_flow_name). Only return the name string.
    output_model:
      suggested_flow_name: str
      final_yaml_to_save: str

  - name: get_config_directory
    type: llm
    tools: True
    tools_selection:
      - shell_command
    tools_auto_approval: True
    system: "Get the astonish config directory path."
    prompt: |
      Run: `python3 -c "import appdirs; print(appdirs.user_config_dir('astonish'))"`
    output_model:
      config_dir: str

  - name: determine_save_path
    type: llm
    system: "Determine the final save path using the suggested name."
    prompt: |
      Config Directory: {config_dir}
      Suggested Name: {suggested_flow_name}
      Construct the full save path: {config_dir}/agents/{suggested_flow_name}.yaml
    output_model:
      final_save_path: str

  - name: write_flow_to_file
    type: llm
    tools: True
    tools_selection:
      - write_file
    system: "Save the YAML content to the specified file path."
    prompt: |
      File Path: {final_save_path}
      YAML Content:
      {current_yaml}

      Save the content to the file. Output confirmation message.
    output_model:
      save_confirmation: str
    user_message:
      - save_confirmation
      - "Flow saved successfully! You can now use by running 'astonish agents run {suggested_flow_name}'"

flow:
  - from: START
    to: get_overall_idea
  - from: get_overall_idea
    to: fetch_available_tools
  - from: fetch_available_tools
    to: generate_or_refine_yaml
  - from: generate_or_refine_yaml
    to: summarize_and_display_yaml
  - from: summarize_and_display_yaml
    to: user_approval
  - from: user_approval
    edges:
      - to: get_yaml_feedback
        condition: "lambda x: x['yaml_feedback'] == 'refine'"
      - to: validate_yaml
        condition: "lambda x: x['yaml_feedback'] == 'approve'"
  - from: get_yaml_feedback
    to: generate_or_refine_yaml
  - from: validate_yaml
    edges:
      - to: generate_or_refine_yaml
        condition: "lambda x: not x.get('is_yaml_valid', True)"
      - to: suggest_flow_name
        condition: "lambda x: x.get('is_yaml_valid', True)"
  - from: suggest_flow_name
    to: get_config_directory
  - from: get_config_directory
    to: determine_save_path
  - from: determine_save_path
    to: write_flow_to_file
  - from: write_flow_to_file
    to: END
