"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6559],{4839:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"concepts/tools","title":"Tools","description":"Tools are a powerful feature in Astonish that allow agents to interact with external systems and perform actions beyond simple text generation. They enable agents to read files, write data, execute shell commands, and more.","source":"@site/docs/concepts/tools.md","sourceDirName":"concepts","slug":"/concepts/tools","permalink":"/astonish/docs/concepts/tools","draft":false,"unlisted":false,"editUrl":"https://github.com/schardosin/astonish/tree/main/docs/docs/concepts/tools.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Nodes","permalink":"/astonish/docs/concepts/nodes"},"next":{"title":"YAML Configuration","permalink":"/astonish/docs/concepts/yaml-configuration"}}');var l=t(4848),s=t(8453);const i={sidebar_position:3},r="Tools",a={},d=[{value:"What are Tools?",id:"what-are-tools",level:2},{value:"Built-in Tools",id:"built-in-tools",level:2},{value:"read_file",id:"read_file",level:3},{value:"write_file",id:"write_file",level:3},{value:"shell_command",id:"shell_command",level:3},{value:"validate_yaml_with_schema",id:"validate_yaml_with_schema",level:3},{value:"chunk_pr_diff",id:"chunk_pr_diff",level:3},{value:"MCP Tools",id:"mcp-tools",level:2},{value:"Using Tools in Agents",id:"using-tools-in-agents",level:2},{value:"1. Using Tools with LLM Nodes",id:"1-using-tools-with-llm-nodes",level:3},{value:"2. Direct Tool Execution with Tool Nodes",id:"2-direct-tool-execution-with-tool-nodes",level:3},{value:"Example: File Reader Agent with LLM",id:"example-file-reader-agent-with-llm",level:3},{value:"Example: Direct Tool Execution",id:"example-direct-tool-execution",level:3},{value:"Tool Approval",id:"tool-approval",level:2},{value:"Tool Input Schemas",id:"tool-input-schemas",level:2},{value:"Tool Output",id:"tool-output",level:2},{value:"1. LLM Processing",id:"1-llm-processing",level:3},{value:"2. Raw Tool Output",id:"2-raw-tool-output",level:3},{value:"3. Direct Tool Output",id:"3-direct-tool-output",level:3},{value:"Creating Custom MCP Tools",id:"creating-custom-mcp-tools",level:2},{value:"Improved ReAct Pattern",id:"improved-react-pattern",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"tools",children:"Tools"})}),"\n",(0,l.jsx)(n.p,{children:"Tools are a powerful feature in Astonish that allow agents to interact with external systems and perform actions beyond simple text generation. They enable agents to read files, write data, execute shell commands, and more."}),"\n",(0,l.jsx)(n.h2,{id:"what-are-tools",children:"What are Tools?"}),"\n",(0,l.jsx)(n.p,{children:"Tools are functions that agents can use to perform specific tasks. They can be:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Invoked by the AI model during the execution of an LLM node"}),"\n",(0,l.jsx)(n.li,{children:"Executed directly through a Tool node without LLM involvement"}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"Tools can:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Read and write files"}),"\n",(0,l.jsx)(n.li,{children:"Execute shell commands"}),"\n",(0,l.jsx)(n.li,{children:"Validate YAML content"}),"\n",(0,l.jsx)(n.li,{children:"Perform web searches (via MCP)"}),"\n",(0,l.jsx)(n.li,{children:"Process and transform data"}),"\n",(0,l.jsx)(n.li,{children:"And much more, depending on the available tools"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"built-in-tools",children:"Built-in Tools"}),"\n",(0,l.jsx)(n.p,{children:"Astonish comes with several built-in tools that are always available:"}),"\n",(0,l.jsx)(n.h3,{id:"read_file",children:"read_file"}),"\n",(0,l.jsx)(n.p,{children:"Reads the contents of a file at the specified path."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"- name: read_document\n  type: llm\n  prompt: |\n    Read the contents of the file at path: {file_path}\n  output_model:\n    file_content: str\n  tools: true\n  tools_selection:\n    - read_file\n"})}),"\n",(0,l.jsx)(n.p,{children:"When the AI model invokes this tool, it will:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Request the file path"}),"\n",(0,l.jsx)(n.li,{children:"Read the file contents"}),"\n",(0,l.jsx)(n.li,{children:"Return the contents as a string"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"write_file",children:"write_file"}),"\n",(0,l.jsx)(n.p,{children:"Writes content to a file at the specified path."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"- name: save_summary\n  type: llm\n  prompt: |\n    Save the following summary to a file:\n    {summary}\n    \n    File path: {output_path}\n  output_model:\n    save_result: str\n  tools: true\n  tools_selection:\n    - write_file\n"})}),"\n",(0,l.jsx)(n.p,{children:"When the AI model invokes this tool, it will:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Request the file path and content"}),"\n",(0,l.jsx)(n.li,{children:"Write the content to the file"}),"\n",(0,l.jsx)(n.li,{children:"Return a confirmation message"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"shell_command",children:"shell_command"}),"\n",(0,l.jsx)(n.p,{children:"Executes a shell command and returns the output."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"- name: list_files\n  type: llm\n  prompt: |\n    List the files in the directory: {directory_path}\n  output_model:\n    file_list: str\n  tools: true\n  tools_selection:\n    - shell_command\n"})}),"\n",(0,l.jsx)(n.p,{children:"When the AI model invokes this tool, it will:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Request the command to execute"}),"\n",(0,l.jsx)(n.li,{children:"Run the command in a shell"}),"\n",(0,l.jsx)(n.li,{children:"Return the stdout and stderr output"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"validate_yaml_with_schema",children:"validate_yaml_with_schema"}),"\n",(0,l.jsx)(n.p,{children:"Validates YAML content against a schema."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"- name: validate_config\n  type: llm\n  prompt: |\n    Validate the following YAML configuration against the schema:\n    \n    Configuration:\n    {yaml_content}\n    \n    Schema:\n    {yaml_schema}\n  output_model:\n    validation_result: str\n  tools: true\n  tools_selection:\n    - validate_yaml_with_schema\n"})}),"\n",(0,l.jsx)(n.p,{children:"When the AI model invokes this tool, it will:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Request the YAML content and schema"}),"\n",(0,l.jsx)(n.li,{children:"Validate the content against the schema"}),"\n",(0,l.jsx)(n.li,{children:"Return validation results or errors"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"chunk_pr_diff",children:"chunk_pr_diff"}),"\n",(0,l.jsx)(n.p,{children:"Parses a PR diff string (git diff format) and breaks it down into reviewable chunks."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"- name: chunk_pr\n  type: tool\n  args:\n    diff_content: {pr_diff}\n  tools_selection:\n    - chunk_pr_diff\n  output_model:\n    pr_chunks: list\n"})}),"\n",(0,l.jsx)(n.p,{children:"When this tool is executed, it will:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Parse the PR diff content"}),"\n",(0,l.jsx)(n.li,{children:"Break it down into reviewable chunks by file and hunk"}),"\n",(0,l.jsx)(n.li,{children:"Return a list of chunks, each containing file path, chunk type, content, and metadata"}),"\n",(0,l.jsx)(n.li,{children:"This is particularly useful for reviewing large PRs by dividing them into smaller, manageable pieces"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"mcp-tools",children:"MCP Tools"}),"\n",(0,l.jsx)(n.p,{children:"In addition to built-in tools, Astonish supports MCP (Model Context Protocol) tools. These are external tools provided by MCP servers that can extend the capabilities of your agents."}),"\n",(0,l.jsx)(n.p,{children:"To use MCP tools:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Configure the MCP server in the MCP configuration file"}),"\n",(0,l.jsx)(n.li,{children:"Enable the tools in your agent's YAML configuration"}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"- name: search_web\n  type: llm\n  prompt: |\n    Search the web for information about: {search_query}\n  output_model:\n    search_results: str\n  tools: true\n  tools_selection:\n    - tavily_search  # An MCP tool for web search\n"})}),"\n",(0,l.jsx)(n.h2,{id:"using-tools-in-agents",children:"Using Tools in Agents"}),"\n",(0,l.jsx)(n.p,{children:"There are two ways to use tools in Astonish:"}),"\n",(0,l.jsx)(n.h3,{id:"1-using-tools-with-llm-nodes",children:"1. Using Tools with LLM Nodes"}),"\n",(0,l.jsx)(n.p,{children:"In this approach, the AI model decides when and how to use tools based on the prompt:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Set ",(0,l.jsx)(n.code,{children:"tools: true"})," in the LLM node configuration"]}),"\n",(0,l.jsxs)(n.li,{children:["Specify the tools to use in the ",(0,l.jsx)(n.code,{children:"tools_selection"})," array"]}),"\n",(0,l.jsx)(n.li,{children:"Write a prompt that instructs the AI model to use the tools"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"2-direct-tool-execution-with-tool-nodes",children:"2. Direct Tool Execution with Tool Nodes"}),"\n",(0,l.jsx)(n.p,{children:"For operations that don't require AI reasoning, you can execute tools directly:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Set ",(0,l.jsx)(n.code,{children:"type: tool"})," in the node configuration"]}),"\n",(0,l.jsxs)(n.li,{children:["Specify the tool to use in the ",(0,l.jsx)(n.code,{children:"tools_selection"})," array"]}),"\n",(0,l.jsxs)(n.li,{children:["Provide arguments to the tool in the ",(0,l.jsx)(n.code,{children:"args"})," object"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"example-file-reader-agent-with-llm",children:"Example: File Reader Agent with LLM"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"description: An agent that reads a file and summarizes its content using LLM\nnodes:\n  - name: get_file_path\n    type: input\n    prompt: |\n      Please enter the path to the file you want to read:\n    output_model:\n      file_path: str\n\n  - name: read_file_content\n    type: llm\n    system: |\n      You are a file reading assistant.\n    prompt: |\n      Read the contents of the file at path: {file_path}\n    output_model:\n      file_content: str\n    tools: true\n    tools_selection:\n      - read_file\n\n  - name: summarize_content\n    type: llm\n    system: |\n      You are a summarization expert.\n    prompt: |\n      Summarize the following content:\n      {file_content}\n    output_model:\n      summary: str\n    user_message:\n      - summary\n\nflow:\n  - from: START\n    to: get_file_path\n  - from: get_file_path\n    to: read_file_content\n  - from: read_file_content\n    to: summarize_content\n  - from: summarize_content\n    to: END\n"})}),"\n",(0,l.jsx)(n.h3,{id:"example-direct-tool-execution",children:"Example: Direct Tool Execution"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"description: An agent that processes a PR diff using direct tool execution\nnodes:\n  - name: get_pr_diff\n    type: llm\n    system: |\n      You are a GitHub CLI expert.\n    prompt: |\n      Use the 'gh pr diff' command to get the diff for PR number {selected_pr}.\n    output_model:\n      retrieval_status: str\n    tools: true\n    tools_selection:\n      - shell_command\n    raw_tool_output:\n      pr_diff: str\n\n  - name: chunk_pr\n    type: tool\n    args:\n      diff_content: {pr_diff}\n    tools_selection:\n      - chunk_pr_diff\n    output_model:\n      pr_chunks: list\n\nflow:\n  - from: START\n    to: get_pr_diff\n  - from: get_pr_diff\n    to: chunk_pr\n  - from: chunk_pr\n    to: END\n"})}),"\n",(0,l.jsx)(n.h2,{id:"tool-approval",children:"Tool Approval"}),"\n",(0,l.jsx)(n.p,{children:"By default, tool usage in LLM nodes requires user approval. This means that when an AI model wants to use a tool, the user will be prompted to approve or deny the tool usage."}),"\n",(0,l.jsxs)(n.p,{children:["You can configure automatic approval for tools using the ",(0,l.jsx)(n.code,{children:"tools_auto_approval"})," field:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"- name: read_file_node\n  type: llm\n  prompt: |\n    Read the file at path: {file_path}\n  output_model:\n    file_content: str\n  tools: true\n  tools_selection:\n    - read_file\n  tools_auto_approval: true  # Tools will be used without user approval\n"})}),"\n",(0,l.jsx)(n.p,{children:"Note that Tool nodes (direct tool execution) do not require approval as they are explicitly configured in the flow."}),"\n",(0,l.jsx)(n.h2,{id:"tool-input-schemas",children:"Tool Input Schemas"}),"\n",(0,l.jsx)(n.p,{children:"Each tool has an input schema that defines the parameters it accepts. The AI model will generate input that conforms to this schema when using the tool."}),"\n",(0,l.jsxs)(n.p,{children:["For example, the ",(0,l.jsx)(n.code,{children:"read_file"})," tool has the following input schema:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"class ReadFileInput {\n  file_path: string;  // The path to the file to be read\n}\n"})}),"\n",(0,l.jsx)(n.p,{children:"The AI model will generate JSON input like:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-json",children:'{\n  "file_path": "/path/to/file.txt"\n}\n'})}),"\n",(0,l.jsx)(n.h2,{id:"tool-output",children:"Tool Output"}),"\n",(0,l.jsx)(n.p,{children:"Tools return their results as strings or structured data. There are two ways to handle tool output:"}),"\n",(0,l.jsx)(n.h3,{id:"1-llm-processing",children:"1. LLM Processing"}),"\n",(0,l.jsxs)(n.p,{children:["By default, in LLM nodes, the AI model will process the tool output and incorporate it into its response. For example, the ",(0,l.jsx)(n.code,{children:"read_file"})," tool returns the file contents as a string, which the AI model can then process and summarize."]}),"\n",(0,l.jsx)(n.h3,{id:"2-raw-tool-output",children:"2. Raw Tool Output"}),"\n",(0,l.jsxs)(n.p,{children:["For large or complex tool outputs, you can use the ",(0,l.jsx)(n.code,{children:"raw_tool_output"})," field in LLM nodes to store the tool output directly in the state without LLM processing:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"- name: get_pr_diff\n  type: llm\n  prompt: |\n    Use the 'gh pr diff' command to get the diff for PR number {selected_pr}.\n  output_model:\n    retrieval_status: str\n  tools: true\n  tools_selection:\n    - shell_command\n  raw_tool_output:\n    pr_diff: str\n"})}),"\n",(0,l.jsxs)(n.p,{children:["In this example, the raw output of the ",(0,l.jsx)(n.code,{children:"shell_command"})," tool is stored directly in the state variable ",(0,l.jsx)(n.code,{children:"pr_diff"}),", while the LLM's response is stored in ",(0,l.jsx)(n.code,{children:"retrieval_status"}),"."]}),"\n",(0,l.jsx)(n.h3,{id:"3-direct-tool-output",children:"3. Direct Tool Output"}),"\n",(0,l.jsxs)(n.p,{children:["In Tool nodes, the tool output is stored directly in the state according to the ",(0,l.jsx)(n.code,{children:"output_model"})," configuration:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"- name: chunk_pr\n  type: tool\n  args:\n    diff_content: {pr_diff}\n  tools_selection:\n    - chunk_pr_diff\n  output_model:\n    pr_chunks: list\n"})}),"\n",(0,l.jsxs)(n.p,{children:["In this example, the output of the ",(0,l.jsx)(n.code,{children:"chunk_pr_diff"})," tool is stored directly in the ",(0,l.jsx)(n.code,{children:"pr_chunks"})," variable."]}),"\n",(0,l.jsx)(n.h2,{id:"creating-custom-mcp-tools",children:"Creating Custom MCP Tools"}),"\n",(0,l.jsx)(n.p,{children:"You can extend Astonish's capabilities by creating custom MCP tools. This involves:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Creating an MCP server that implements the tools"}),"\n",(0,l.jsx)(n.li,{children:"Configuring the server in the MCP configuration file"}),"\n",(0,l.jsx)(n.li,{children:"Using the tools in your agents through either LLM nodes or Tool nodes"}),"\n"]}),"\n",(0,l.jsxs)(n.p,{children:["For more information on creating custom MCP tools, see the ",(0,l.jsx)(n.a,{href:"/docs/api/tools/mcp-tools",children:"MCP Tools"})," documentation."]}),"\n",(0,l.jsx)(n.h2,{id:"improved-react-pattern",children:"Improved ReAct Pattern"}),"\n",(0,l.jsx)(n.p,{children:"Astonish implements an improved ReAct (Reasoning and Acting) pattern for tool usage in LLM nodes. This pattern allows the AI model to:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Reason"})," about what tool to use and how to use it"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Act"})," by executing the chosen tool"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Observe"})," the results of the tool execution"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Continue reasoning"})," based on the observations"]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"The ReAct pattern is implemented automatically when you enable tools in an LLM node. The AI model will:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Generate a thought about what to do next"}),"\n",(0,l.jsx)(n.li,{children:"Choose a tool to execute"}),"\n",(0,l.jsx)(n.li,{children:"Provide input for the tool"}),"\n",(0,l.jsx)(n.li,{children:"Receive the tool's output as an observation"}),"\n",(0,l.jsx)(n.li,{children:"Generate a new thought based on the observation"}),"\n",(0,l.jsx)(n.li,{children:"Either use another tool or provide a final answer"}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"This pattern enables more complex reasoning and multi-step tool usage within a single node."}),"\n",(0,l.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Choose the right approach"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Use LLM nodes with tools when you need AI reasoning to decide when and how to use tools"}),"\n",(0,l.jsx)(n.li,{children:"Use Tool nodes for direct execution when the operation is straightforward and doesn't require AI reasoning"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Be specific in prompts"}),": Clearly instruct the AI model on when and how to use tools"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Use raw_tool_output for large data"}),": When dealing with large outputs like file contents or API responses, use the ",(0,l.jsx)(n.code,{children:"raw_tool_output"})," field to avoid overwhelming the LLM"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Handle errors"}),": Consider what might happen if a tool fails and provide guidance"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Use tools judiciously"}),": Only enable tools that are necessary for the node's function"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Consider security"}),": Be careful with tools that can modify the system or access sensitive data"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Test thoroughly"}),": Test your agents with various inputs to ensure tools are used correctly"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,l.jsx)(n.p,{children:"To learn more about tools in Astonish, check out:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"/docs/api/tools/internal-tools",children:"Internal Tools"})," for details on built-in tools"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"/docs/api/tools/mcp-tools",children:"MCP Tools"})," for information on extending Astonish with custom tools"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"/docs/tutorials/using-tools",children:"Tutorials"})," for examples of using tools in agents"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>r});var o=t(6540);const l={},s=o.createContext(l);function i(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:i(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);